{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signature_Verif_Hssain_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u64W2WClSgcA",
        "outputId": "ddd52463-1208-443d-9e18-437a7f8d4f33"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aabdQyYCUzU-"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/drive/MyDrive/sign/Sign_Verif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_z-0JXKlMKJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JnDokz6UgjT"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "import skimage.io\r\n",
        "import os \r\n",
        "import tqdm\r\n",
        "import glob\r\n",
        "import tensorflow \r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from skimage.io import imread, imshow\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.color import grey2rgb\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPooling2D, Conv2D\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "from keras.callbacks import Callback,ModelCheckpoint\r\n",
        "from keras.models import Sequential,load_model\r\n",
        "from keras.layers import Dense, Dropout\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "import keras.backend as K\r\n",
        "\r\n",
        "#import tensorflow_addons as tfa\r\n",
        "#from tensorflow.keras.metrics import Metric\r\n",
        "#from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\r\n",
        "from typeguard import typechecked\r\n",
        "from typing import Optional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrX71MZBVAqq"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74cHjTtbVGt0"
      },
      "source": [
        "  train_datagen = ImageDataGenerator(rescale = 1./255, \r\n",
        "                                   validation_split = 0.2,\r\n",
        "                                  \r\n",
        "        rotation_range=5,\r\n",
        "        width_shift_range=0.2,\r\n",
        "        height_shift_range=0.2,\r\n",
        "        shear_range=0.2,\r\n",
        "        #zoom_range=0.2,\r\n",
        "        horizontal_flip=True,\r\n",
        "        vertical_flip=True,\r\n",
        "        fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                  validation_split = 0.2)\r\n",
        "\r\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255\r\n",
        "                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doCMnck2VSNN",
        "outputId": "fc028cf4-20fa-40c3-83da-840373a39a0d"
      },
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = '/content/drive/MyDrive/sign/Sign_Verif/dataset',\r\n",
        "                                                   target_size = (224,224),\r\n",
        "                                                   class_mode = 'categorical',\r\n",
        "                                                   subset = 'training',\r\n",
        "                                                   batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1416 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfTulaErVnSk",
        "outputId": "ab40dbd1-e1ac-4bba-b7a3-c703bf776597"
      },
      "source": [
        "valid_dataset = valid_datagen.flow_from_directory(directory = '/content/drive/MyDrive/sign/Sign_Verif/dataset',\r\n",
        "                                                  target_size = (224,224),\r\n",
        "                                                  class_mode = 'categorical',\r\n",
        "                                                  subset = 'validation',\r\n",
        "                                                  batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 352 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4BccIoyVpfQ",
        "outputId": "8a2509d6-9559-4d4f-cf90-59a3b42ad1b8"
      },
      "source": [
        "test_dataset = test_datagen.flow_from_directory(directory = '/content/drive/MyDrive/sign/Sign_Verif/sample_Signature',\r\n",
        "                                                  target_size = (224,224),\r\n",
        "                                                  class_mode = 'categorical',\r\n",
        "                                                  batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 329 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GIfNdxYV5KA",
        "outputId": "cbe43bd4-68a3-42b8-9826-fa49cac7fc71"
      },
      "source": [
        "def build_model():\r\n",
        "    \r\n",
        "    '''Sequential Model creation'''\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(16,(3,3),padding='same',strides=(2, 2),input_shape = (224,224,3),activation='relu'))\r\n",
        "    \r\n",
        "    model.add(Conv2D(32,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    \r\n",
        "    model.add(Conv2D(32,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    \r\n",
        "    model.add(Conv2D(64,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    model.add(Conv2D(64,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    model.add(Conv2D(64,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    \r\n",
        "    model.add(Conv2D(64,(3,3),padding='same',strides=(2, 2),activation='relu'))\r\n",
        "    \r\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=1,padding = 'same'))\r\n",
        "    \r\n",
        "    \r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(100))\r\n",
        "    model.add(Dense(2))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    \r\n",
        "    return model\r\n",
        "    \r\n",
        "model = build_model()\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 112, 112, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 2, 2, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               25700     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 169,518\n",
            "Trainable params: 169,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6-JEIFFWQmr"
      },
      "source": [
        "def f1_score(y_true, y_pred): #taken from old keras source code\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\r\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCsLtQDoWWyJ"
      },
      "source": [
        "METRICS = [\r\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\r\n",
        "      tf.keras.metrics.Precision(name='precision'),\r\n",
        "      tf.keras.metrics.Recall(name='recall'),  \r\n",
        "      tf.keras.metrics.AUC(name='auc'),\r\n",
        "        f1_score,\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKFsR4nwWZer"
      },
      "source": [
        "def exponential_decay(lr0, s):\r\n",
        "    def exponential_decay_fn(epoch):\r\n",
        "        return lr0 * 0.1 **(epoch / s)\r\n",
        "    return exponential_decay_fn\r\n",
        "\r\n",
        "exponential_decay_fn = exponential_decay(0.01, 5) # when i run it for 50 epochs\r\n",
        "\r\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22lnWkEEWizt"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=METRICS)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSpNK0l5WpHL"
      },
      "source": [
        "history=model.fit(train_dataset,\r\n",
        "                        validation_data=valid_dataset,\r\n",
        "                        epochs = 40,\r\n",
        "                        verbose = 1,\r\n",
        "                         callbacks=lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}